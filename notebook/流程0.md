我先把入口 frontend/main.py 和 kv_router.rs 主调度代码读一遍，再结合 push_router/scheduler/prefill_router/vLLM handler，把整条链路按“可点击路径 + 行号”的形式重新梳理一遍，并补足更细节的执行过程。
先回答你两个点：

1. **“能 click 跳转到代码处”**  
   在你这个工作区里，一般 IDE/Qoder 支持下面几种形式点击跳转：
   - 绝对路径 + 行号：  
     `/home/liutong/myNode/codes/dynamo-0112/lib/llm/src/kv_router/push_router.rs:51-132`
   - 或相对路径 + 行号：  
     `lib/llm/src/kv_router/push_router.rs:51-132`  

   所以我后面都会用这种格式标注，比如：  
   `lib/llm/src/kv_router/push_router.rs:51-132`  
   你在 IDE 里 Ctrl+点击/Command+点击基本都能直接跳过去。

2. **“上面所说的过程，再详细点”**  
   我这次会按“从 HTTP 请求开始，一直追到 vLLM engine.generate 的每一步”，且每个关键环节都给“可点击路径+行号”。

---

## 1. Frontend 启动 + Router 配置

**文件**：  
`/home/liutong/myNode/codes/dynamo-0112/components/src/dynamo/frontend/main.py`

### 1.1 启动命令

例如示例脚本里类似这样启动前端（你之前搜索到的）：

```bash
python -m dynamo.frontend \
  --router-mode kv \
  --http-port 8000 \
  --router-reset-states
```

对应解析参数的位置：

- `components/src/dynamo/frontend/main.py:82-260`

重点参数：

- `--router-mode`：`round-robin | random | kv`
- `--kv-cache-block-size`：KV block 大小
- `--kv-overlap-score-weight`：Prefill 阶段 KV 命中权重
- `--router-temperature`：软采样温度
- `--use-kv-events / --no-kv-events`：是否用 worker 上报的 KV 事件，而不是“根据路由决策推测 KV 状态”
- `--router-track-output-blocks`：是否在生成期间按 block 追踪输出负载
- `--enforce-disagg`：强制 PD 分离（下文 PrefillRouter 会用到）

在解析完这些参数后，frontend 会构建：

- `RouterConfig`（包含 `RouterMode` 等）
- `KvRouterConfig`（包含 overlap 权重、温度、事件线程数等）

然后交给 `dynamo.llm.make_engine` 去创建整条 pipeline（HTTP → Preprocessor → Router → Backend）。

---

## 2. kv_router 顶层模块：组件拼装

**文件**：  
`lib/llm/src/kv_router.rs:1-120`

这里把几个子模块拼起来：

```rust
pub mod config;
pub mod metrics;
pub mod prefill_router;
pub mod publisher;
pub mod push_router;
pub mod recorder;
pub mod scheduler;
pub mod sequence;
pub mod subscriber;
pub mod worker_query;

pub use config::{KvRouterConfig, RouterConfigOverride};
pub use prefill_router::PrefillRouter;
pub use push_router::KvPushRouter;
```

也定义了：

- `Indexer`：背后用 RadixTree 维护 KV 前缀索引
- `WorkerSelector` trait：调度层的“如何从 worker 列表中选一个”的接口（Default 实现用 cost function）

这意味着：**在 frontend 创建 Router 的时候，会把 KvScheduler + KvIndexer + KvPushRouter + PrefillRouter 拼成一套**。

---

## 3. PrefillRouter：在 PD 分离场景下编排 Prefill + Decode

**文件（核心逻辑）**：  
`lib/llm/src/kv_router/prefill_router.rs:94-667`  

你可以先点到这段看 generate 实现。

### 3.1 PrefillRouter 结构

```rust
pub struct PrefillRouter {
    prefill_router: OnceLock<InnerPrefillRouter>, // KV 模式或 Simple Router
    model_manager: Arc<ModelManager>,
    endpoint_id: OnceLock<EndpointId>,
    cancel_token: CancellationToken,
    router_mode: RouterMode,
    enforce_disagg: bool,
    model_name: String,
}
```

- `InnerPrefillRouter` 是两种模式的封装：
  - `KvRouter(Arc<KvPushRouter>)`：KV 感知路由
  - `SimpleRouter(Arc<PushRouter<...>>)`：轮询 / 随机 / 直连

### 3.2 PrefillRouter.generate：请求生命周期

入口：  
`lib/llm/src/kv_router/prefill_router.rs:505-667`

核心流程拆开：

1. **检查是否激活**

   ```rust
   if self.prefill_router.get().is_none() {
       if self.enforce_disagg {
           return Err(anyhow::anyhow!(PrefillError::NotActivated));
       }
       return next.generate(context.map(|_| req)).await; // 退化为 Decode-only
   }
   ```

   - 未激活 + `enforce_disagg=false` → 直接把请求丢给后面的 decode router（PD 分离等于关掉）
   - 未激活 + `enforce_disagg=true` → 认为配置要求 PD 分离，但 prefill 不可用，直接报错

2. **设置阶段为 Prefill**

   ```rust
   if req.tracker.is_none() {
       req.tracker = Some(Arc::new(RequestTracker::new()));
   }
   let tracker = req.tracker.as_ref().unwrap();
   let prefill_phase_permit = tracker.set_phase(RequestPhase::Prefill).await;
   ```

   - `RequestTracker` 在整个 lifecycle 里记录：阶段、TTFT、ITL、OSL 等
   - 这里先标记请求进入 **Prefill** 阶段

3. **构造 Prefill 请求：max_tokens = 1**

   ```rust
   let original_max_tokens = req.stop_conditions.max_tokens;
   let mut prefill_req = req.clone();
   prefill_req.stop_conditions.max_tokens = Some(1);
   ```

   - Prefill 只需要算出 KV，不需要长输出，所以只生成 1 个 token

4. **选择 Prefill Worker + 构建 bootstrap_info**

   ```rust
   let preselected_worker = prefill_req
       .routing
       .as_ref()
       .and_then(|r| r.prefill_worker_id);

   if let Some((worker_id, dp_rank, bootstrap_info)) =
       self.build_bootstrap_info(&prefill_req, preselected_worker).await
   {
       // ...
   }
   ```

   `build_bootstrap_info` 在：  
   `lib/llm/src/kv_router/prefill_router.rs:267-343`

   关键逻辑：

   - 如果 `prefill_worker_id` 已经指定，就直接用
   - 否则如果 `router_mode.is_kv_routing()`：
     - 从 `InnerPrefillRouter::KvRouter` 拿到 `KvPushRouter.chooser`（KvRouter）
     - 调用 `chooser.find_best_match(...)` 做 KV 感知路由（见后面 KvScheduler 部分）
   - 拿到 `(worker_id, dp_rank)` 后，通过 `model_manager.get_disaggregated_endpoint` 拿到：
     - `bootstrap_host`
     - `bootstrap_port`
   - 随机生成 `bootstrap_room`
   - 组合出 `BootstrapInfo`，写入请求的 `bootstrap_info` 字段

   这些信息最终会被 Decode Worker 用于通过 NIXL 拉取 Prefill Worker 上的 KV。

5. **Bootstrap 优化路径：Prefill 放后台**

   如果 `build_bootstrap_info` 成功：

   ```rust
   // 非 KV 模式时需要消耗掉一次 router 的轮询
   if !self.router_mode.is_kv_routing()
       && let Some(router) = self.prefill_router.get()
   {
       router.select_next_worker();
   }

   let routing = prefill_req.routing_mut();
   routing.prefill_worker_id = Some(worker_id);
   routing.dp_rank = Some(dp_rank);
   prefill_req.bootstrap_info = Some(bootstrap_info.clone());

   // 创建 child context，spawn prefill 任务
   let prefill_context = Context::with_id(prefill_req, request_id.clone());
   engine_ctx.link_child(prefill_context.context());

   self.spawn_prefill_task(prefill_context, Some(worker_id), prefill_phase_permit);
   ```

   - **Prefill 在后台执行**（`spawn_prefill_task`）：  
     `lib/llm/src/kv_router/prefill_router.rs:441-471`
   - 主线程不等 Prefill 完成，直接准备进入 Decode，提升并发度

6. **Prefill 原始路径：同步等待 Prefill 完成**

   如果 `build_bootstrap_info` 失败（比如找不到合适的 disagg endpoint），则走“原始路径”：

   ```rust
   drop(prefill_phase_permit);  // 我们会等 Prefill 完，只要 Prefill OK 就能切到 Decode
   let result = self.call_prefill(prefill_context).await;
   ```

   `call_prefill` 内部使用 `execute_prefill`：
   - 调 `InnerPrefillRouter::generate_to_worker`
   - 收完 Prefill 流
   - 解析 `LLMEngineOutput` 的：
     - `disaggregated_params`
     - `completion_usage.prompt_tokens_details`
   - 返回 `PrefillResult` 和（如果有）`prefill_worker_id + dp_rank`

7. **Prefill 成功后，进入 Decode**

   无论是后台路径还是原始路径，Prefill 完成后都会走到这里：

   ```rust
   if let Some(ref tracker) = req.tracker {
       let _decode_permit = tracker.set_phase(RequestPhase::Decode).await;
   }

   let mut decode_req = req;

   // 如果 Prefill 返回了结果，把 prefill_result 放进请求
   if let Some(prefill_result) = maybe_prefill_result {
       decode_req.prefill_result = Some(prefill_result);
   }

   // 恢复原始 max_tokens
   decode_req.stop_conditions.max_tokens = original_max_tokens;

   // 注入 bootstrap_info （如果有）
   if let Some(info) = bootstrap_info {
       decode_req.bootstrap_info = Some(info);
   }

   // 关键：对 Decode 路由设置 RouterConfigOverride
   decode_req.router_config_override = Some(RouterConfigOverride {
       overlap_score_weight: Some(0.0),
       ..existing_override.unwrap_or_default()
   });

   // 把 decode_req 往后传给 Decode Router（通常还是 KvPushRouter）
   let decode_request = context.map(|_| decode_req);
   next.generate(decode_request).await
   ```

   这就是你之前看到的：**Decode 阶段 `overlap_score_weight = 0`，只看负载，不看本地 KV 命中**。

---

## 4. KvPushRouter：选择 Worker + 调用 PushRouter

**文件**：  
`lib/llm/src/kv_router/push_router.rs:39-132`  
`lib/llm/src/kv_router/push_router.rs:158-400`

你可以直接点击：  
`lib/llm/src/kv_router/push_router.rs:47-132`  
`lib/llm/src/kv_router/push_router.rs:158-400`

### 4.1 结构

```rust
pub struct KvPushRouter {
    inner: PushRouter<PreprocessedRequest, Annotated<LLMEngineOutput>>,
    pub chooser: Arc<KvRouter>,
}
```

- `inner`：真正把请求推到 Rust→Python worker 的路由器（按 instance ID）
- `chooser`：`KvRouter`，负责基于 KV 索引 + Scheduler 选择最优 `WorkerWithDpRank`

### 4.2 select_worker：三种情况

`lib/llm/src/kv_router/push_router.rs:51-132`

```rust
async fn select_worker(
    &self,
    context_id: &str,
    request: &PreprocessedRequest,
    phase: RequestPhase,
    is_query_only: bool,
    handle_local_updates: bool,
) -> Result<WorkerSelection, Error> {
    let routing = request.routing.as_ref();
    let lora_name = routing.and_then(|r| r.lora_name.clone());
    let dp_rank = routing.and_then(|r| r.dp_rank).unwrap_or(0);
    let expected_output_tokens = routing.and_then(|r| r.expected_output_tokens);

    // 1. 优先用 preselected worker
    let preselected_id = match phase {
        RequestPhase::Prefill => routing.and_then(|r| r.prefill_worker_id.or(r.backend_instance_id)),
        RequestPhase::Decode  => routing.and_then(|r| r.decode_worker_id.or(r.backend_instance_id)),
        RequestPhase::Aggregated => routing.and_then(|r| r.backend_instance_id),
    };

    let Some(id) = preselected_id else {
        // 2. 没有预选，调用 KvRouter::find_best_match
        let (best_worker, overlap_amount) = self
            .chooser
            .find_best_match(
                Some(context_id),
                &request.token_ids,
                request.router_config_override.as_ref(),
                !is_query_only,
                lora_name,
            )
            .await?;

        return Ok(WorkerSelection {
            instance_id: best_worker.worker_id,
            dp_rank: best_worker.dp_rank,
            overlap_amount,
        });
    };

    // 3. 有预选id：算一下 overlap，但绝大部分情况下仅用于统计
    let worker = WorkerWithDpRank::new(id, dp_rank);
    let overlap_blocks = self
        .chooser
        .get_overlap_blocks(&request.token_ids, worker)
        .await?;

    if !is_query_only && handle_local_updates {
        self.chooser
            .add_request(
                context_id.to_string(),
                &request.token_ids,
                overlap_blocks,
                expected_output_tokens,
                worker,
                lora_name,
            )
            .await;
    }

    Ok(WorkerSelection {
        instance_id: id,
        dp_rank,
        overlap_amount: overlap_blocks,
    })
}
```

非常重要的一点：

- **Prefill 阶段**，如果没预选 → `find_best_match` 中的 `overlap_weight` 一般是 1.0 → 优先命中 KV
- **Decode 阶段**，PrefillRouter 已经把 `overlap_score_weight` 改成 0 → `find_best_match` 时只看负载（下面讲 Scheduler）

### 4.3 generate：生命周期管理

`lib/llm/src/kv_router/push_router.rs:158-400`

关键步骤：

1. 解析 `context_id / is_query_only / handle_local_updates / phase`
2. 调 `select_worker` 拿到 `instance_id, dp_rank, overlap_amount`
3. 如果 `use_kv_events=false`，基于这次路由决策更新本地 Radix 索引（KVApprox 模式）
4. 在 tracker 上记录：
   - `record_kv_hit`（overlap）
   - `record_isl`（输入长度 + 命中长度）
   - `record_worker_full`（记录选了哪个 worker、dp_rank、worker_type）
5. 如果 `is_query_only`：  
   返回一个只包含 `disaggregated_params.worker_id` 和 `token_ids` 的单次响应（不推给后端）
6. 正常路径下：
   - 给 request 写上 `routing.dp_rank`
   - 调 `inner.direct(..., instance_id)` 把请求推给具体 worker（Python vLLM 进程）
   - 用 async stream 包裹响应流：
     - 第一批真正有 token 时，`mark_prefill_completed`
     - 每跨一个 block 更新 `add_output_block`（如果开启 track_output_blocks）
     - 结束时 `free(request_id)` 释放调度状态

---

## 5. KvScheduler：真正的“成本函数选节点”

**文件**：  
`lib/llm/src/kv_router/scheduler.rs:467-595`

点击：  
`lib/llm/src/kv_router/scheduler.rs:467-595`

### 5.1 DefaultWorkerSelector::select_worker

```rust
fn select_worker(
    &self,
    workers: &HashMap<WorkerId, ModelRuntimeConfig>,
    request: &SchedulingRequest,
    block_size: u32,
) -> Result<WorkerSelectionResult, KvSchedulerError> {
    assert!(request.isl_tokens > 0);

    if workers.is_empty() {
        return Err(KvSchedulerError::NoEndpoints);
    }

    let isl = request.isl_tokens;
    let request_blocks = isl.div_ceil(block_size as usize);
    let overlaps = &request.overlaps.scores;

    let decode_blocks = &request.decode_blocks;
    let prefill_tokens = &request.prefill_tokens;

    let mut worker_logits = HashMap::new();

    // 决定 overlap_weight（Prefill=1.0；Decode=0）
    let overlap_weight = request
        .router_config_override
        .as_ref()
        .and_then(|cfg| cfg.overlap_score_weight)
        .unwrap_or(self.kv_router_config.overlap_score_weight);

    for (worker_id, config) in workers.iter() {
        let data_parallel_size = config.data_parallel_size;

        for dp_rank in 0..data_parallel_size {
            let worker = WorkerWithDpRank::new(*worker_id, dp_rank);

            // prefix overlap block数
            let overlap = *overlaps.get(&worker).unwrap_or(&0);

            // 预填充tokens（包括已有的KV负载）
            let prefill_token = *prefill_tokens.get(&worker).unwrap_or(&isl);
            let potential_prefill_block = (prefill_token as f64) / (block_size as f64);

            // decode blocks，如果没统计，就用 prefill_blocks 估个下限
            let decode_block = *decode_blocks
                .get(&worker)
                .unwrap_or(&(potential_prefill_block.floor() as usize))
                as f64;

            // 关键：成本函数
            let logit = overlap_weight * potential_prefill_block + decode_block;

            worker_logits.insert(worker, logit);
        }
    }

    // softmax_sample + tree_size 作为平局决胜
    let temperature = request
        .router_config_override
        .as_ref()
        .and_then(|cfg| cfg.router_temperature)
        .unwrap_or(self.kv_router_config.router_temperature);
    let candidates = softmax_sample(&worker_logits, temperature);

    let best_worker = if candidates.len() > 1 {
        *candidates
            .iter()
            .min_by_key(|worker| {
                request
                    .overlaps
                    .tree_sizes
                    .get(worker)
                    .copied()
                    .unwrap_or(0)
            })
            .expect("candidates should not be empty")
    } else {
        candidates[0]
    };

    Ok(WorkerSelectionResult {
        worker: best_worker,
        required_blocks: request_blocks as u64,
        overlap_blocks: overlaps.get(&best_worker).copied().unwrap_or(0),
    })
}
```

**总结：**

- Prefill 阶段：`overlap_weight > 0` → **KV 命中 + 负载** 综合
- Decode 阶段：`overlap_weight = 0` → 只看 `decode_blocks`（负载）

`decode_blocks` / `prefill_tokens` 的来源：

```rust
let (decode_blocks, prefill_tokens) = slots_clone
    .potential_blocks_and_tokens(
        request.token_seq.clone(),
        request.isl_tokens,
        request.overlaps.clone(),
    )
    .await;
```

这里 `slots_clone` 是 `ActiveSequencesMultiWorker`，记录所有正在运行请求，对每个 worker 估算如果加一个新请求，prefill & decode 负载会变成多少。

---

## 6. vLLM Worker 侧：Prefill + Decode 具体行为

**文件**：  
`components/src/dynamo/vllm/handlers.py:1239-1600`

你可以点：  
`components/src/dynamo/vllm/handlers.py:1239-1363`（DecodeWorkerHandler）  
`components/src/dynamo/vllm/handlers.py:1451-1600`（PrefillWorkerHandler）

### 6.1 PrefillWorkerHandler：生成 KV + 返回 disaggregated_params

```python
class PrefillWorkerHandler(BaseWorkerHandler):
    async def generate(self, request, context):
        request_id = context.id()
        # 只走 token-in-token-out
        async for chunk in self._generate_token_mode(request, context, request_id):
            yield chunk

    async def _generate_token_mode(self, request, context, request_id):
        multi_modal_data = await self._extract_multimodal_data(request)

        # 构造 prompt (TokenPrompt 或 EmbedsPrompt)
        prompt, embedding_sequence_length, error = self._build_prompt_from_request(
            request, request_id, multi_modal_data, log_prefix="Prefill "
        )
        # ...

        sampling_params = build_sampling_params(
            request, self.default_sampling_params, self.model_max_len
        )

        # 关键：配置 kv_transfer_params，告诉 vLLM 这是“Prefill-only”
        if sampling_params.extra_args is None:
            sampling_params.extra_args = {}
        sampling_params.extra_args["kv_transfer_params"] = {
            "do_remote_decode": True,
        }
        # 只生成 1 token
        sampling_params.max_tokens = 1
        sampling_params.min_tokens = 1

        # LoRA 处理略...

        gen = self.engine_client.generate(
            prompt,
            sampling_params,
            request_id,
            data_parallel_rank=dp_rank,
            lora_request=lora_request,
            trace_headers=trace_headers,
        )

        async for res in gen:
            token_ids = res.outputs[0].token_ids if res.outputs else []
            output = {
                "token_ids": list(token_ids),
                "disaggregated_params": (
                    {"kv_transfer_params": res.kv_transfer_params}
                    if res.kv_transfer_params
                    else None
                ),
                "completion_usage": BaseWorkerHandler._build_completion_usage(
                    request_output=res,
                    embedding_sequence_length=embedding_sequence_length,
                ),
            }
            yield output
```

这里几点：

- 对 vLLM 来说，这个请求是一次普通的 generate，但通过 `extra_args["kv_transfer_params"]` 告诉 engine：
  - 只做 Prefill（生成1个token）
  - 并准备好 KV 传输相关参数，填入 `res.kv_transfer_params`
- 这些 `kv_transfer_params` 最终被打包到 `disaggregated_params` → Rust PrefillRouter 在 S5 阶段提取出来，并在 Decode 阶段透传回 Decode Worker

### 6.2 DecodeWorkerHandler：消费 disaggregated_params，继续生成

```python
class DecodeWorkerHandler(BaseWorkerHandler):
    async def _generate_token_mode(self, request, context, request_id):
        multi_modal_data = await self._extract_multimodal_data(request)
        prompt, embedding_sequence_length, error = self._build_prompt_from_request(
            request, request_id, multi_modal_data
        )

        sampling_params = build_sampling_params(
            request, self.default_sampling_params, self.model_max_len
        )

        # 关键：从 prefill_result 里拿回 kv_transfer_params
        prefill_result = request.get("prefill_result")
        if prefill_result and isinstance(prefill_result, dict):
            kv_params = prefill_result.get("disaggregated_params", {}).get(
                "kv_transfer_params"
            )
        else:
            kv_params = None

        if kv_params is not None:
            if sampling_params.extra_args is None:
                sampling_params.extra_args = {}
            sampling_params.extra_args["kv_transfer_params"] = kv_params
            logger.debug(
                f"Using disaggregated params from prefill for request {request_id}"
            )

        # LoRA、dp_rank、trace_headers 处理略...

        async for tok in self.generate_tokens(
            prompt,
            sampling_params,
            request_id,
            data_parallel_rank=dp_rank,
            lora_request=lora_request,
            embedding_sequence_length=embedding_sequence_length,
            trace_headers=trace_headers,
        ):
            # 把 Prefill 的 prompt_tokens_details 合并到最终 usage 里
            if prefill_result is not None and "completion_usage" in tok:
                tok["completion_usage"]["prompt_tokens_details"] = prefill_prompt_tokens_details
            yield tok
```

这一步里：

- Decode Worker **不再重做 Prefill**，而是利用 `kv_transfer_params`（内部包含 remote host/port/room 或 block IDs 等信息）
- vLLM engine 内部通过 NIXL / 内部 KV 机制从 Prefill Worker 拿到 KV Cache
- 然后正常执行剩余 decode

---

## 7. 整体时序（更细粒度）

把上面所有代码串起来，形成一个更细的时序（以 vLLM + PD 分离 + KV Router 模式为例）：

1. Client 调用 HTTP 接口（OpenAI 格式）
2. Frontend main.py 解析请求 → 交给 Preprocessor → 构造 `PreprocessedRequest`
3. PrefillRouter.generate：
   - 确保 tracker 存在
   - 标记 Phase = Prefill
   - 构造 `prefill_req`（max_tokens=1）
   - 调 `build_bootstrap_info`：
     - 若无预选 worker：
       - 调 `KvRouter.find_best_match` → 内部用 KvIndexer + KvScheduler 做 KV-aware 选 worker
     - 通过 ModelManager 选出真实 Prefill Worker 的 host/port（disagg endpoint）
     - 生成 `BootstrapInfo`（host/port/room）
   - 写入 `prefill_req.routing.prefill_worker_id / dp_rank / bootstrap_info`
   - Bootstrap 成功 → `spawn_prefill_task` 在后台发给 Prefill Worker
4. KvPushRouter.generate（Prefill 阶段）：
   - `select_worker`：
     - 有 `prefill_worker_id` → 直接用
   - 调 `inner.direct(updated_request, instance_id)` 把请求发给对应 vLLM Prefill Worker
5. PrefillWorkerHandler.generate（Python）：
   - 解码 multimodal
   - 构造 vLLM prompt + sampling_params
   - 设置 `extra_args["kv_transfer_params"].do_remote_decode = True`
   - 调 `engine_client.generate(...)`：
     - vLLM 只算 Prefill
     - 生成 1 个 token + KV transfer 元数据 `kv_transfer_params`
   - 返回：
     - `token_ids`
     - `disaggregated_params = { "kv_transfer_params": kv_transfer_params }`
   - Rust PrefillRouter.execute_prefill 解析这个结果，形成 `PrefillResult`
6. Prefill 完成后（或后台路径中第一条输出返回后）：
   - PrefillRouter 将 `prefill_result` 注入 Decode 请求
   - 将 `router_config_override.overlap_score_weight = 0.0`（Decode 阶段只看负载）
   - Phase 切到 Decode
   - 调下游 Decode Router（通常还是 KvPushRouter）
7. KvPushRouter.generate（Decode 阶段）：
   - `select_worker`：
     - 如果有 `decode_worker_id` 就用它，否则：
       - 调 `KvRouter.find_best_match`，此时 `overlap_weight=0` → 只看 decode 负载
   - 调 `inner.direct` 发给选好的 Decode Worker
   - 在流中：
     - 第一批 token 到达时：`mark_prefill_completed` + 记录 TTFT
     - 每跨 block：`add_output_block` + 更新 ITL / OSL
     - 流结束：`free(request_id)`
8. DecodeWorkerHandler.generate（Python）：
   - 解析 `prefill_result` 中的 `disaggregated_params.kv_transfer_params`
   - 注入 `sampling_params.extra_args["kv_transfer_params"]`
   - 调 vLLM engine.generate：
     - vLLM 依据 kv_transfer_params 与 Prefill Worker 协调 KV 传输（NIXL/GPU-to-GPU）
     - 继续生成剩余 token，并流式返回
   - Frontend 把 token 流转成 OpenAI 格式返回给 Client

---

如果你愿意，下一步我可以做两件事：

1. 只围绕 `lib/llm/src/kv_router` 写一版“**你自己的 PD 路由插件**”设计建议（成本函数、状态结构、KV 索引结构如何抽象出来）。
2. 或者选一段你最关心的代码（比如 `KvRouter.find_best_match` 或 `ActiveSequencesMultiWorker::potential_blocks_and_tokens`），我帮你把函数体一行行解释。